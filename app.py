import streamlit as st
import joblib
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression

# --- CONFIGURACIÃ“N DE PÃGINA ---
st.set_page_config(
    page_title="Detector de DepresiÃ³n", 
    page_icon="ðŸ§ ",
    layout="centered"
)

# --- FUNCIÃ“N DE CARGA ---
@st.cache_resource
def cargar_modelo():
    # Busca el archivo en la misma carpeta donde estÃ¡ app.py
    nombre_archivo = 'modelo_depresion.pkl' # AsegÃºrate que este sea el nombre correcto
    try:
        data = joblib.load(nombre_archivo)
        return data
    except FileNotFoundError:
        return None

# --- FUNCIÃ“N PARA MOSTRAR PESOS ---
def explicar_prediccion(modelo, vectorizer, texto_procesado):
    """
    Extrae los coeficientes de las palabras presentes en el texto.
    Solo funciona para modelos lineales (LogisticRegression, LinearSVC).
    """
    try:
        # 1. Verificar si el modelo tiene coeficientes (RBF no tiene)
        if not hasattr(modelo, 'coef_'):
            st.warning("âš ï¸ Este modelo no soporta la visualizaciÃ³n de pesos directos (posible kernel RBF).")
            return

        # 2. Obtener el vocabulario y los pesos
        # get_feature_names_out() es para scikit-learn versiones nuevas
        # si te da error, cambia por get_feature_names()
        feature_names = vectorizer.get_feature_names_out()
        
        # 3. Transformar solo este texto para ver quÃ© indices activa
        texto_vec = vectorizer.transform([texto_procesado])
        indices_activos = texto_vec.nonzero()[1] # Ãndices de las palabras encontradas
        
        datos_palabras = []
        
        # 4. Cruzar palabras encontradas con sus pesos
        for idx in indices_activos:
            palabra = feature_names[idx]
            peso = modelo.coef_[0][idx]
            impacto = "ðŸ”´ Depresivo" if peso > 0 else "ðŸŸ¢ Sano/Neutro"
            datos_palabras.append({
                "Palabra": palabra,
                "Peso (Coeficiente)": round(peso, 4),
                "Tendencia": impacto
            })
            
        # 5. Crear DataFrame y ordenar por impacto absoluto
        if datos_palabras:
            df = pd.DataFrame(datos_palabras)
            df = df.sort_values(by="Peso (Coeficiente)", ascending=False)
            
            st.markdown("##### Â¿Por quÃ© el modelo dijo esto?")
            st.dataframe(
                df.style.map(lambda x: 'color: red' if x > 0 else 'color: green', subset=['Peso (Coeficiente)']),
                use_container_width=True,
                hide_index=True
            )
        else:
            st.info("No se encontraron palabras conocidas en el vocabulario del modelo.")

    except Exception as e:
        st.error(f"No se pudo explicar la predicciÃ³n: {e}")

# --- INTERFAZ PRINCIPAL ---
def main():
    st.title("ðŸ§  Detector de Patrones Depresivos")
    st.markdown("""
        Este modelo analiza texto para identificar indicadores lingÃ¼Ã­sticos de depresiÃ³n.
        
        *Nota: Esto es una herramienta de demostraciÃ³n y NO sustituye un diagnÃ³stico profesional.*
        """)
    
    # Cargar modelo
    pack = cargar_modelo()
    
    if pack is None:
        st.error(f"âŒ No se encuentra el archivo 'modelo_depresion.pkl'.")
        st.warning("AsegÃºrate de haber descargado el archivo .pkl de Colab y ponerlo en esta misma carpeta.")
        st.stop()

    modelo = pack['modelo']
    vectorizer = pack['vectorizer']

    # Ãrea de texto
    st.subheader("Ingresa el texto a analizar:")
    texto_usuario = st.text_area("Comentario:", height=150, placeholder="Escribe aquÃ­ en inglÃ©s...")

    if st.button("Analizar Sentimiento"):
        if not texto_usuario.strip():
            st.warning("El texto estÃ¡ vacÃ­o.")
        else:
            with st.spinner("Procesando..."):
                try:
                    # 1. Limpieza (Truncamiento)
                    texto_truncado = " ".join(texto_usuario.split()[:25])
                    
                    # 2. VectorizaciÃ³n
                    texto_vec = vectorizer.transform([texto_truncado])
                    
                    # 3. PredicciÃ³n
                    prediccion = modelo.predict(texto_vec)[0]
                    
                    # Intentamos sacar probabilidad
                    confianza = 0.0
                    try:
                        probs = modelo.predict_proba(texto_vec)[0]
                        confianza = probs[1] if prediccion == 1 else probs[0]
                    except:
                        pass # Si el modelo no tiene predict_proba

                    st.divider()

                    if prediccion == 1:
                        st.error("âš ï¸ Resultado: POSIBLE DEPRESIÃ“N")
                        if confianza > 0:
                            st.write(f"Confianza del modelo: **{confianza*100:.1f}%**")
                        st.info("El modelo detectÃ³ palabras y estructuras asociadas a la clase 'DepresiÃ³n'.")
                    else:
                        st.success("âœ… Resultado: NO DEPRESIÃ“N")
                        if confianza > 0:
                            st.write(f"Confianza del modelo: **{confianza*100:.1f}%**")

                    # --- NUEVA SECCIÃ“N: VISUALIZAR PESOS ---
                    with st.expander("ðŸ” Ver pesos de las palabras (ExplicaciÃ³n)"):
                        explicar_prediccion(modelo, vectorizer, texto_truncado)
                    # ---------------------------------------

                except Exception as e:
                    st.error(f"Error al procesar: {e}")

    # Texto explicativo inferior (se mantiene igual)
    st.markdown("""
    ---
    ### GuÃ­a de InterpretaciÃ³n de Casos
    
    **Grupo 1: Los "Rescatados" (Sutiles)**
    * "I just want to stay in bed all day." -> DeberÃ­a marcar DepresiÃ³n (Anhedonia).
    
    **Grupo 2: Los "Falsos Positivos Esperados"**
    * "I hate rainy days." -> Posible Falsa Alarma por palabras negativas ("hate").
    
    **Grupo 3: La Prueba de Sanidad**
    * "I am very happy with my life." -> Debe marcar Sano.
    """)

if __name__ == '__main__':
    main()
